{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ceddcb1abd644e4c912e394c873448fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Claude 3.5 Sonnet (2024-06-20)",
              "Claude 3 Opus (2024-02-29)",
              "Claude 3 Sonnet (2024-02-29)",
              "Claude 3 Haiku (2024-03-07)"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_75e79bfd7aca4236a6f19455ef0ee1d6",
            "style": "IPY_MODEL_d07c512b3f40402caa622f0e70c3a462"
          }
        },
        "75e79bfd7aca4236a6f19455ef0ee1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07c512b3f40402caa622f0e70c3a462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2be91af36a9403db1048cb4497d2693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "System:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b1ff5b92c9c443c5853b5425743ded04",
            "placeholder": "Define a role: You are a...",
            "rows": null,
            "style": "IPY_MODEL_e5c6da1befd246d2a3a2fb22407e847f",
            "value": "You are a helpful assistant."
          }
        },
        "b1ff5b92c9c443c5853b5425743ded04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e5c6da1befd246d2a3a2fb22407e847f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8702bbe5b04da69a7a64dfebc02a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Prompt:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cc60f317313043cfb9e75afda0f3e48c",
            "placeholder": "Type something...",
            "rows": null,
            "style": "IPY_MODEL_5810efcfb6c14c128fdbdacf2274e40f",
            "value": "Enter your prompt here..."
          }
        },
        "cc60f317313043cfb9e75afda0f3e48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5810efcfb6c14c128fdbdacf2274e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddfa340b5cc846d49faf66c6d233c838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8c3e844e121d44c3b0d53f785e2addf2",
            "style": "IPY_MODEL_50f50e311edf4e7f97b14db6830378e6",
            "tooltip": ""
          }
        },
        "8c3e844e121d44c3b0d53f785e2addf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f50e311edf4e7f97b14db6830378e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session4_Anthropic_Text_Completion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <ins>Session 4</ins>.: **IBM Skills Build: Embeddable AI Live Technical Lab**\n",
        "\n",
        "**NB:** See [#8 Feature üöÄ Anthropic Text Completions + API:( Github.com)](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/issues/8)\n",
        "\n",
        "> #### **Objective**: *Understand the theory and hands-on implementation of*: <br> 1Ô∏è‚É£ Embedded AI- Hands-on Chatbots <sup><b><small>Interactive, CoLab</small></b></sup>\n",
        ">> - Embedded AI- Hands-on Chatbots using `Python`, `Flask`, `HTML`, `CSS`, and `Javascript`.\n",
        ">> - Integrate the chatbot with *Anthropic*  latest / freemium model to give it a high level of intelligence and the ability to understand and respond to user requests\n",
        "\n",
        "> #### <br> 2Ô∏è‚É£ Embedded AI - IBM Watson Speach to Text <sup><b><small>Not Covered, External Platform</small></b></sup>\n",
        ">> - Implement `IBM Watson Speech-to-Text` functionality to allow the chatbot to understand voice input from users\n",
        "\n",
        ">> - Implement `IBM Watson Text-to-Speech` functionality to allow the chatbot to communicate with users through voice outputg\n",
        "\n",
        "- **URL**: [https://skills.yourlearning.ibm.com/activity/PLAN-CB1CC0D21AFB](https://skills.yourlearning.ibm.com/activity/PLAN-CB1CC0D21AFB \"Programme for Artifical Intelligence: eLearning on IBM.com (Login required)\")  <small><sup><strong> eLearning, Login</strong></sup></small><br>\n",
        "- **Share**: [Create a Voice Assistant with OpenAI's GPT-3/4 and IBM Watson](https://skills.yourlearning.ibm.com/activity/SN-COURSE-V1:IBMSKILLSNETWORK+GPXX0IWWEN+V1 \"eLearning on IBM.com (Login required\")  <small><sup><strong>eLearning, Login</strong></sup></small>\n",
        "- **Recording**: [Recording: Live Technical Session 4](https://skills.yourlearning.ibm.com/activity/URL-15DDC14F0206 \"Video: IBM's (Login required\")  <small><sup><strong> eLearning, Login</strong></sup></small><br>\n",
        "- **CoLab: Source Notebook**: [https://colab.research.google.com/drive/1TZekNH-QvntOgj0ujc7PMQ27s4PQ0-qi#scrollTo=odmjGQ-FaiHq](https://colab.research.google.com/drive/1TZekNH-QvntOgj0ujc7PMQ27s4PQ0-qi#scrollTo=odmjGQ-FaiHq \"Authors: Marty Bradly's Session 4 Embeddable AI - Hands on with Chatbots\")\n",
        "  - Original by author: Marty Bradly: [LinkedIn](https://www.linkedin.com/in/martybradley/), [Website](https://www.evergreen-ai.com/), [GitHub @marty916](https://github.com/marty916 \"Marty Bradly [July, 2024], Last accessed: July 2024\")"
      ],
      "metadata": {
        "id": "-MuVZBIxWOzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUDIENCES**<br>\n",
        "- <small>Notebook for technical audiences.\n",
        "- See [README](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/README.md) and [Sessions.md](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/Sessions.md) for business and product audiences</small>"
      ],
      "metadata": {
        "id": "WhYXVdsoaNot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "X2zitn-uahaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚ö†Ô∏è<ins>Notices</ins>‚ö†Ô∏è**\n",
        "\n",
        "#### <ins>Anthropic API is paid/by credits.</ins>\n",
        "\n",
        "> - This session requires access to Anthropic's, (or another AI provider), API Key.\n",
        "> - These API may require a credit/debit card to purchase credits.\n",
        "> - Purchase a small amount of credits.\n",
        "> - Do not expose your proof of concept solution to the public access.\n",
        "> - Condfigure and run on `https://localhost`.\n",
        "\n",
        "#### <ins>API Keys as Secrets.</ins>\n",
        "\n",
        "> - Utilise strong confidentiality practices when using API Keys.\n",
        "> - For Colab, add the key to the environmental variables.\n",
        "> - OpenAI Environmental Key is `'ANTHROPIC_API_KEY'`.\n",
        "> - Do not expose directly your own API Key value.\n",
        "> - Do not commit your OpenAI key to Github.\n",
        "> - Use System environmental varaibles, `.env` files (`.gitignore`'d) or a secrets management solution for secure secrets transport.\n",
        "\n",
        "NOTE: The reason you create a secret is to hide your API Key from others.  \n",
        "- If anyone has access to your key, it will be used to track token usage and could end up with you getting charged for extra tokens.  \n",
        "- Also, if you check in your notebook to github, if you have an exposed API Key in your code github may block the checkin.\n",
        "- This is for your security."
      ],
      "metadata": {
        "id": "h_Nnwd8qbJ8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "Zxcp0irkcpt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub\n",
        "\n",
        "- **IBM-Skills-AI_Colab-Sessions**:\n",
        "    - [README](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/README.md)\n",
        "    - [Sessions Summary](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/Sessions.md)\n",
        "    - [notebook-labs/Session4_Anthropic_Text_Completion](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session4_Anthropic_Text_Completion.ipynb \"@iPoetDev: GitHub.com:  IBM-Skills-AI_Colab-Sessions: Session3_VAE Juypter Notebook\")"
      ],
      "metadata": {
        "id": "cWrN8MG4aYBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "WW-nL_MmgzPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps\n",
        "\n",
        "1.   [Install](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/#scrollTo=xoYevZJPaO7M&line=1&uniqifier=1 \"Install necessary components\")\n",
        "2.   [Initatiate API Key](#scrollTo=odmjGQ-FaiHq&line=1&uniqifier=1 \"Instantiate an OpenAI client passing in your API Key.\")\n",
        "3.   [Model Functions](#scrollTo=2S6giTDNd1-a&line=1&uniqifier=1 \"Reusable function using gpt-4o-mini model for completions.\")\n",
        "4.   [Examples](#scrollTo=5nJTCSVOet8a&line=1&uniqifier=1 \"Examples: Prompts, Print Output \")\n",
        "5.   [Interactive Prompt](#scrollTo=LKw5xIe4e25E&line=1&uniqifier=1 \"Create an interactive prompt.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H7qBu7fEaX_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. <ins>Install necessary components</ins>\n",
        "\n",
        "- Install Anthropic Libraries <sup><ins>1</ins></sup>\n",
        "- Import Anthropic\n",
        "\n",
        "#### Explore Anthropic SDK\n",
        "\n",
        "- <sup><ins>1</ins></sup> : [Anthropic SDK](https://docs.anthropic.com/en/api/client-sdks)\n",
        "\n",
        "   - <sub>[![Anthropic Claude](https://img.shields.io/badge/Anthropic-Claude-000000?logo=anthropic&logoColor=white)](https://www.anthropic.com) <sup>|</sup> [![Anthropic Claude API](https://img.shields.io/badge/Anthropic_API-Platform_Keys_(üí≥üîê)-000000?logo=anthropic&logoColor=white)](https://console.anthropic.com/api-keys) <sup>|</sup> [![Anthropic API Reference](https://img.shields.io/badge/Anthropic_API-Reference-000000?logo=anthropic&logoColor=white)](https://console.anthropic.com/docs/api-reference) <sup>|</sup> [![GitHub](https://img.shields.io/badge/Anthropic-GitHub-181717?logo=github&logoColor=white)](https://github.com/anthropic) <sup>|</sup> [![PyPI](https://img.shields.io/badge/Anthropic-PyPI-3775A9?logo=pypi&logoColor=white)](https://pypi.org/project/anthropic/)</sub>"
      ],
      "metadata": {
        "id": "xoYevZJPaO7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--HsA5LXTQ_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e839d1c-a6f4-46e7-d53d-4977dee6dd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Downloading anthropic-0.33.0-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m866.9/866.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.33.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic"
      ],
      "metadata": {
        "id": "1BI4HTKkTeNQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "T7gVaxBvlu3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. <ins>Instantiate an Antropic client passing in your API Key.</ins>\n",
        "\n",
        "#### Anthropic Client\n",
        "1. [Create an API Key-NightFallAI](https://www.nightfall.ai/ai-security-101/anthropic-claude-api-key)\n",
        "\n",
        "2. Click the \"key\" icon to the left to the \"secrets\" dialog box\n",
        "3. Select \"+ Add new secret\"\n",
        "4. Set Name to `'ANTHROPIC_API_KEY'` and paste your newly created *OpenAI API Key* into `'Value'` <sup><ins>2</ins></sup>\n",
        "5. Make sure \"Notebook access\" is on (check mark will show up to the right if it is on.\n",
        "\n",
        "- <sup><ins>2</ins></sup> : [Anthropic Claude API Key: The Essential Guide](https://platform.openai.com/docs/overview)\n",
        "\n",
        "#### Google CoLab Secrets\n",
        "\n",
        "- Configure your code by storing environment variables, file paths, or keys.\n",
        "- Values stored here are private, visible only to you and the notebooks that you select.\n",
        "- Secret name cannot contain spaces; use underscores, all caps.\n",
        "- `userdata` import is relabeled `as secrets` for clarity of use."
      ],
      "metadata": {
        "id": "odmjGQ-FaiHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Anthropic client\n",
        "\n",
        "## Import CoLabs User Secrets\n",
        "from google.colab import userdata as secrets\n",
        "\n",
        "## Define Anthropic Client\n",
        "client = anthropic.Anthropic(\n",
        "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    api_key=secrets.get('IBM_ANTHROPIC_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "CnKXv_RFUj03"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UCy2m8TznLqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "eCsHVBNoEQ7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] Success: Key Loaded (2024-08-09)"
      ],
      "metadata": {
        "id": "NFgfX7JXRPGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. <ins>Reusable function using gpt-4o-mini model for completions.</ins>\n",
        "\n",
        "- Go to the OpenAI website\n",
        "    - Check models that are available:<br>\n",
        "      ***Currently**\n",
        "        - .\n",
        "        - .\n",
        "    - Change the model <sup><ins>3</ins></sup>\n",
        "    - Evaluate the different responses per model.\n",
        "\n",
        "- <sup><ins>3</ins></sup> : [OpenAI Models](https://platform.openai.com/docs/models)"
      ],
      "metadata": {
        "id": "2S6giTDNd1-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: Orginal"
      ],
      "metadata": {
        "id": "4TAJT1DxqmHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Anthropic Message API/Docs\n",
        "\n",
        "> Our models are trained to operate on alternating user and assistant\n",
        "conversational turns. When creating a new Message, you specify the prior\n",
        "conversational turns with the messages parameter, and the model then generates\n",
        "the next Message in the conversation.\n",
        "\n",
        "> Each input message must be an object with a role and content. You can\n",
        "specify a single user-role message, or you can include multiple user and\n",
        "assistant messages. The first message must always use the user role.\n",
        "\n",
        "> If the final message uses the assistant role, the response content will\n",
        "continue immediately from the content in that message. This can be used to\n",
        "constrain part of the model's response.\n",
        "\n",
        "Example with a single user message:\n",
        "\n",
        "        json \\[{ \"role\": \"user\", \"content\": \"Hello, Claude\" }\\]\n",
        "\n",
        "Example with multiple conversational turns:\n",
        "\n",
        "        json \\[{ \"role\": \"user\", \"content\": \"Hello there.\" }, { \"role\": \"assistant\", \"content\": \"Hi, I'm Claude. How can I help you?\" }, { \"role\": \"user\", \"content\": \"Can you explain LLMs in plain English?\" }\\]\n",
        "\n",
        "Example with a partially-filled response from Claude:\n",
        "\n",
        "        json \\[{\"role\": \"user\",\"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"}, { \"role\": \"assistant\", \"content\": \"The best answer is (\" }\\]\n",
        "\n",
        "> Each input message content may be either a single string or an array of\n",
        "content blocks, where each block has a specific type. Using a string for\n",
        "content is shorthand for an array of one content block of type \"text\". The\n",
        "following input messages are equivalent:\n",
        "\n",
        "        json { \"role\": \"user\", \"content\": \"Hello, Claude\" }\n",
        "\n",
        "        json { \"role\": \"user\", \"content\": \\[{ \"type\": \"text\", \"text\": \"Hello, Claude\" }\\] }\n",
        "\n",
        "> Starting with Claude 3 models, you can also send image content blocks:\n",
        "\n",
        "              json {\"role\": \"user\", \"content\": \\[{\"type\": \"image\",\"source\": {\"type\": \"base64\",\"media\\_type\": \"image/jpeg\",\"data\": \"/9j/4AAQSkZJRg...\"}}, { \"type\": \"text\", \"text\": \"What is in this image?\" }\\]}\n",
        "\n",
        "> We currently support the base64 source type for images, and the image/jpeg,\n",
        "image/png, image/gif, and image/webp media types. See examples for more input examples.\n",
        "\n",
        "> Note that if you want to include a system prompt, you can use\n",
        "the top-level system parameter ‚Äî there is no \"system\" role for input\n",
        "messages in the Messages API."
      ],
      "metadata": {
        "id": "Apj_fuPxVfo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oW16VMoISjSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_text(model, user_message,\n",
        "                  role_prompting,\n",
        "                  role_user=\"user\",\n",
        "                  token_max=1024):\n",
        "    \"\"\"Generates text using the Anthropic API.\n",
        "\n",
        "    Args:\n",
        "        model: The Anthropic model to use.\n",
        "        user_message: The message to send to the API.\n",
        "        role_prompting: The system parameter to set Claude‚Äôs role.\n",
        "        role_user: The role of the user sending the message.\n",
        "        token_max: The maximum number of tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        The response from the Anthropic API.\n",
        "    \"\"\"\n",
        "    response = client.messages.create(\n",
        "        model=model,\n",
        "        max_tokens=token_max,\n",
        "        system=role_prompting, # <-- role prompt\n",
        "        messages=[\n",
        "            {\"role\": role_user,\n",
        "             \"content\": \"Hi there ...\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Hi I am Claude and I will\"},\n",
        "            {\"role\": role_user,\n",
        "             \"content\": user_message},\n",
        "        ]\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "lHrcb0a8TjjN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] Success: Generate_Text() (2024-08-09)"
      ],
      "metadata": {
        "id": "5PDAslJQlCoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: Refactored\n",
        "\n",
        "- Atomic single principle functions.\n",
        "- Cleaner Code\n",
        "- Modular"
      ],
      "metadata": {
        "id": "rA3KqwJWqqEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "ANTHROPIC_MODEL = \"claude-3-5-sonnet-20240620\"\n",
        "SYSTEM_ROLE = \"You are a helpful assistant.\"\n",
        "user_instruction = \"Once upon a time in a land far, far away, there was a\""
      ],
      "metadata": {
        "id": "Now10YIyrXeg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] Success: Variables defined (2024-08-09)"
      ],
      "metadata": {
        "id": "ce9Ulfy_lGmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Call the Anthropic API via Python SDK\n",
        "# 3. Generate the Output\n",
        "\n",
        "# 2.\n",
        "def call_anthropic_api(user_instruction,\n",
        "                       system_role,\n",
        "                       model=\"claude-3-5-sonnet-20240620\"):\n",
        "    \"\"\"Calls the Anthropic API and returns the response.\n",
        "\n",
        "        Args:\n",
        "        user_instruction: The message to send to the API.\n",
        "        system_role: The system parameter to set Claude‚Äôs role.\n",
        "        model: The Anthropic model to use, defaults to claude-3-5-sonnet-20240620.\n",
        "\n",
        "    Returns:\n",
        "        The response from the Anthropic API.\n",
        "\n",
        "    \"\"\"\n",
        "    response = generate_text(model, user_instruction, system_role)\n",
        "    return response\n",
        "\n",
        "\n",
        "def clean_output(response, line_sep=\"\\n\", content_type=\"text\"):\n",
        "    \"\"\" Clean Output \"\"\"\n",
        "    extracted_out = response[0].text\n",
        "    cleaned_out = extracted_out.replace(\"\\n\\n\", line_sep)\n",
        "    return cleaned_out\n",
        "\n",
        "# 3.\n",
        "def generate_output(user_instruction, system_role = \"You are a helpful assistant.\",  model = ANTHROPIC_MODEL):\n",
        "    \"\"\"Generates ouput, based on the (validated) user's instruction.\n",
        "\n",
        "\n",
        "       This function would/could\n",
        "       i) handle input validation of the user instruction, system role and model.\n",
        "       ii) handle any last minute formating of the output.\n",
        "\n",
        "    Args:\n",
        "        user_instruction: The message to send to the API.\n",
        "        system_role: The system parameter to set Claude‚Äôs role.\n",
        "        model: The Anthropic model to use, defaults to ANTHROPIC_MODEL .\n",
        "\n",
        "    Errors:\n",
        "        All these raise a ValueError, as follows:\n",
        "        The Task, i.e. user_instruction, must be a non-empty string.\n",
        "        The role prompt for Claud, i.e. system_role, must be a non-empty string.\n",
        "        The selected Anthropic Model, i.e. model, must be a non-empty string.\n",
        "\n",
        "    Returns:\n",
        "        The response's content, the output, from the Anthropic API.\n",
        "\n",
        "    \"\"\"\n",
        "    if not isinstance(user_instruction, str) or not user_instruction:\n",
        "        raise ValueError(\"The Task, i.e. user_instruction, must be a non-empty string.\")\n",
        "    if not isinstance(system_role, str) or not system_role:\n",
        "        raise ValueError(\"The role prompt for Claud, i.e. system_role, must be a non-empty string.\")\n",
        "    if not isinstance(model, str) or not model:\n",
        "        raise ValueError(\"The selected Anthropic Model, i.e. model, must be a non-empty string.\")\n",
        "\n",
        "    output = call_anthropic_api(user_instruction, system_role, model).content\n",
        "\n",
        "    return clean_output(output, \"<br>\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0C6S_x6Sp0GX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] Success: Refactored Functions (2024-08-09)"
      ],
      "metadata": {
        "id": "P6vO0m5ZlKX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "7L29p6G9rjmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. <ins>Example</ins>\n",
        "- **`Task`**: Write a fairy tale\n",
        "- Steps\n",
        "    1. Assign prompt\n",
        "    2. Generate\n",
        "        - a: Original Function: Generate Text\n",
        "        - b: Refactored Function: Generate Output\n",
        "    3. Display Output"
      ],
      "metadata": {
        "id": "5nJTCSVOet8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Example prompt\n",
        "message_content = user_instruction\n",
        "\n",
        "# 2.a. Original: Generate text\n",
        "generated_out = generate_output(message_content)\n",
        "\n",
        "# 2.b. Refactored: Generate output\n",
        "\n",
        "from ast import mod\n",
        "# Import IPython widgets for interactive input\n",
        "from IPython.display import display\n",
        "\n",
        "# Display the output\n",
        "display(\"**Prompt:** \" + message_content)\n",
        "display(\"--- --- --- \\n --- --- ---\")\n",
        "display(f\"**Generated Text:** {generated_out}\")\n"
      ],
      "metadata": {
        "id": "FUJxYWq1TppO",
        "outputId": "afeb72b9-05aa-4442-fe91-a3a3c601b345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'**Prompt:** Once upon a time in a land far, far away, there was a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'--- --- --- \\n --- --- ---'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'**Generated Text:** Once upon a time in a land far, far away, there was a beautiful kingdom nestled between towering mountains and lush forests. This kingdom was known for its kind-hearted rulers, brave knights, and a magical secret that had protected the realm for centuries.<br>At the heart of this kingdom stood a majestic castle with gleaming spires that seemed to touch the clouds. Within its walls lived Princess Aria, a young woman known for her wisdom and compassion. Despite her royal upbringing, Aria longed for adventure and to explore the world beyond the castle walls.<br>One day, as Princess Aria was walking through the castle gardens, she stumbled upon an ancient stone archway hidden behind overgrown vines. Curious, she brushed away the greenery to reveal strange symbols etched into the weathered stone. Little did she know, this discovery would set in motion a grand adventure that would change her life and the fate of the kingdom forever...<br>Would you like me to continue the story from here?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] ‚ùå Fail: Your credit balance is too low to access the Claude API. Please go to Plans & Billing to upgrade or purchase credits. (2024-08-09, 20:02)\n",
        "- [x] ‚úÖ Success: Purchased 10 euro credits\n",
        "- [x] ‚úÖ Sucess: Swicthed from print to ipython.display for better text handling, and extracted the coprrect element in the response.\n",
        "- [x] ‚úÖ Sucess: added a clean response function for the generated output."
      ],
      "metadata": {
        "id": "WAJQCp6QlQy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "SP5S96pZEUBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. <ins>Create an interactive prompt.</ins>\n",
        "1. Start a story like, \"Once upon a time there was a princess fighting for her\" HINT: leave it hanging so the model knows to start generating\n",
        "2. Ask, \"How do I bake a cake?\""
      ],
      "metadata": {
        "id": "LKw5xIe4e25E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_models_vals = [\"claude-3-5-sonnet-20240620\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"] # Replace with actual model names\n",
        "\n",
        "available_models = [(\"Claude 3.5 Sonnet (2024-06-20)\", \"claude-3-5-sonnet-20240620\"),\n",
        "                    (\"Claude 3 Opus (2024-02-29)\", \"claude-3-opus-20240229\"),\n",
        "                    (\"Claude 3 Sonnet (2024-02-29)\", \"claude-3-sonnet-20240229\"),\n",
        "                    (\"Claude 3 Haiku (2024-03-07)\", \"claude-3-haiku-20240307\")]"
      ],
      "metadata": {
        "id": "2JoHuOBxmAaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Just a little unfamilar with iPython and Google Collab interactivity with generated widgets, so for now, text input is limited in this medium."
      ],
      "metadata": {
        "id": "sSa5rn3f_QY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import mod\n",
        "# Import IPython widgets for interactive input\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create a text box for user input\n",
        "role_box = widgets.Textarea(\n",
        "    value=SYSTEM_ROLE,\n",
        "    placeholder='Define a role: You are a...',\n",
        "    description='System:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100%'),\n",
        "    tooltip='Using role prompting, to improve accuarcy, tailor a tone, and improve focus of Claude per task.'\n",
        ")\n",
        "\n",
        "\n",
        "# Create a text box for user input\n",
        "prompt_box = widgets.Textarea(\n",
        "    value='Enter your prompt here...',\n",
        "    placeholder='Type something...',\n",
        "    description='Prompt:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100%'),\n",
        "    tooltip='Define a task for Claude, in alignment with the role assigned.'\n",
        ")\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=available_models,\n",
        "    value=available_models[0][1], # Default to the first model's value\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        "    tooltip='Select a model. Defaults to Claude Sonet 3.5 (2024-06-20)'\n",
        ")\n",
        "\n",
        "# Create a button to generate text\n",
        "button = widgets.Button(description=\"Generate Text\")\n",
        "\n",
        "# Function to handle button click\n",
        "def on_button_click(b):\n",
        "    model = model_dropdown.value\n",
        "    system = role_box.value\n",
        "    prompt = prompt_box.value\n",
        "    generated_text = generate_output(prompt, system, model)\n",
        "    print(\"Prompt:\", prompt)\n",
        "    print(\"Generated Text:\", generated_text)\n",
        "\n",
        "# Attach the function to the button click event\n",
        "button.on_click(on_button_click)\n",
        "\n",
        "# Display the model selector, text box and button\n",
        "display(model_dropdown, role_box)\n",
        "\n",
        "display('           ----------------------------')\n",
        "\n",
        "display(prompt_box, button)\n"
      ],
      "metadata": {
        "id": "JWxgJ17pTts5",
        "outputId": "99d2d215-cb0c-478d-8be1-6298464031c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "ceddcb1abd644e4c912e394c873448fa",
            "75e79bfd7aca4236a6f19455ef0ee1d6",
            "d07c512b3f40402caa622f0e70c3a462",
            "e2be91af36a9403db1048cb4497d2693",
            "b1ff5b92c9c443c5853b5425743ded04",
            "e5c6da1befd246d2a3a2fb22407e847f",
            "fe8702bbe5b04da69a7a64dfebc02a90",
            "cc60f317313043cfb9e75afda0f3e48c",
            "5810efcfb6c14c128fdbdacf2274e40f",
            "ddfa340b5cc846d49faf66c6d233c838",
            "8c3e844e121d44c3b0d53f785e2addf2",
            "50f50e311edf4e7f97b14db6830378e6"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Model:', options=(('Claude 3.5 Sonnet (2024-06-20)', 'claude-3-5-sonnet-20240620'), ('Cl‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceddcb1abd644e4c912e394c873448fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='You are a helpful assistant.', description='System:', layout=Layout(width='100%'), placeholder‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2be91af36a9403db1048cb4497d2693"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'           ----------------------------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='Enter your prompt here...', description='Prompt:', layout=Layout(width='100%'), placeholder='T‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe8702bbe5b04da69a7a64dfebc02a90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Generate Text', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddfa340b5cc846d49faf66c6d233c838"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] ‚úÖ Success: No errors in code when cell runs\n",
        "- [x] ‚ùå Interactivity of widgets, i.e. widget event handling, disabled/blocks text input into System and Prompt. Further research needed."
      ],
      "metadata": {
        "id": "bS86RelF__dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "e6JqCHkpEWcm"
      }
    }
  ]
}