{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/Session4_Anthropic_Text_Completion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <ins>Session 4</ins>.: **IBM Skills Build: Embeddable AI Live Technical Lab**\n",
        "\n",
        "**NB:** See [#8 Feature üöÄ Anthropic Text Completions + API:( Github.com)](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/issues/8)\n",
        "\n",
        "> #### **Objective**: *Understand the theory and hands-on implementation of*: <br> 1Ô∏è‚É£ Embedded AI- Hands-on Chatbots <sup><b><small>Interactive, CoLab</small></b></sup>\n",
        ">> - Embedded AI- Hands-on Chatbots using `Python`, `Flask`, `HTML`, `CSS`, and `Javascript`.\n",
        ">> - Integrate the chatbot with *Anthropic*  latest / freemium model to give it a high level of intelligence and the ability to understand and respond to user requests\n",
        "\n",
        "> #### <br> 2Ô∏è‚É£ Embedded AI - IBM Watson Speach to Text <sup><b><small>Not Covered, External Platform</small></b></sup>\n",
        ">> - Implement `IBM Watson Speech-to-Text` functionality to allow the chatbot to understand voice input from users\n",
        "\n",
        ">> - Implement `IBM Watson Text-to-Speech` functionality to allow the chatbot to communicate with users through voice outputg\n",
        "\n",
        "- **URL**: [https://skills.yourlearning.ibm.com/activity/PLAN-CB1CC0D21AFB](https://skills.yourlearning.ibm.com/activity/PLAN-CB1CC0D21AFB \"Programme for Artifical Intelligence: eLearning on IBM.com (Login required)\")  <small><sup><strong> eLearning, Login</strong></sup></small><br>\n",
        "- **Share**: [Create a Voice Assistant with OpenAI's GPT-3/4 and IBM Watson](https://skills.yourlearning.ibm.com/activity/SN-COURSE-V1:IBMSKILLSNETWORK+GPXX0IWWEN+V1 \"eLearning on IBM.com (Login required\")  <small><sup><strong>eLearning, Login</strong></sup></small>\n",
        "- **Recording**: [Recording: Live Technical Session 4](https://skills.yourlearning.ibm.com/activity/URL-15DDC14F0206 \"Video: IBM's (Login required\")  <small><sup><strong> eLearning, Login</strong></sup></small><br>\n",
        "- **CoLab: Source Notebook**: [https://colab.research.google.com/drive/1TZekNH-QvntOgj0ujc7PMQ27s4PQ0-qi#scrollTo=odmjGQ-FaiHq](https://colab.research.google.com/drive/1TZekNH-QvntOgj0ujc7PMQ27s4PQ0-qi#scrollTo=odmjGQ-FaiHq \"Authors: Marty Bradly's Session 4 Embeddable AI - Hands on with Chatbots\")\n",
        "  - Original by author: Marty Bradly: [LinkedIn](https://www.linkedin.com/in/martybradley/), [Website](https://www.evergreen-ai.com/), [GitHub @marty916](https://github.com/marty916 \"Marty Bradly [July, 2024], Last accessed: July 2024\")"
      ],
      "metadata": {
        "id": "-MuVZBIxWOzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUDIENCES**<br>\n",
        "- <small>Notebook for technical audiences.\n",
        "- See [README](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/README.md) and [Sessions.md](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/Sessions.md) for business and product audiences</small>"
      ],
      "metadata": {
        "id": "WhYXVdsoaNot"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJX9tRjnO8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "X2zitn-uahaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚ö†Ô∏è<ins>Notices</ins>‚ö†Ô∏è**\n",
        "\n",
        "#### <ins>OpenAI API is paid/freemium.</ins>\n",
        "\n",
        "> - This session requires access to Anthropic's, (or another AI provider), API Key.\n",
        "> - These API may require a credit/debit card.\n",
        "> - Keep usage to a minimum, within thresholds, and usage will be free.\n",
        "> - Do not expose your proof of concept solution to the public access.\n",
        "> - Condfigure and run on `https://localhost`.\n",
        "\n",
        "#### <ins>API Keys as Secrets.</ins>\n",
        "\n",
        "> - Utilise strong confidentiality practices when using API Keys.\n",
        "> - For Colab, add the key to the environmental variables.\n",
        "> - OpenAI Environmental Key is `'ANTHROPIC_API_KEY'`.\n",
        "> - Do not expose directly your own API Key value.\n",
        "> - Do not commit your OpenAI key to Github.\n",
        "> - Use System environmental varaibles, `.env` files (`.gitignore`'d) or a secrets management solution for secure secrets transport.\n",
        "\n",
        "NOTE: The reason you create a secret is to hide your API Key from others.  \n",
        "- If anyone has access to your key, it will be used to track token usage and could end up with you getting charged for extra tokens.  \n",
        "- Also, if you check in your notebook to github, if you have an exposed API Key in your code github may block the checkin.\n",
        "- This is for your security."
      ],
      "metadata": {
        "id": "h_Nnwd8qbJ8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "Zxcp0irkcpt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub\n",
        "\n",
        "- **IBM-Skills-AI_Colab-Sessions**:\n",
        "    - [README](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/README.md)\n",
        "    - [Sessions Summary](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/Sessions.md)\n",
        "    - [notebook-labs/Session4_OpenAI_Text_Completion](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session4_OpenAI_Text_Completion.ipynb \"@iPoetDev: GitHub.com:  IBM-Skills-AI_Colab-Sessions: Session3_VAE Juypter Notebook\")"
      ],
      "metadata": {
        "id": "cWrN8MG4aYBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "WW-nL_MmgzPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps\n",
        "\n",
        "1.   [Install](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/#scrollTo=xoYevZJPaO7M&line=1&uniqifier=1 \"Install necessary components\")\n",
        "2.   [Initatiate API Key](#scrollTo=odmjGQ-FaiHq&line=1&uniqifier=1 \"Instantiate an OpenAI client passing in your API Key.\")\n",
        "3.   [Model Functions](#scrollTo=2S6giTDNd1-a&line=1&uniqifier=1 \"Reusable function using gpt-4o-mini model for completions.\")\n",
        "4.   [Examples](#scrollTo=5nJTCSVOet8a&line=1&uniqifier=1 \"Examples: Prompts, Print Output \")\n",
        "5.   [Interactive Prompt](#scrollTo=LKw5xIe4e25E&line=1&uniqifier=1 \"Create an interactive prompt.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H7qBu7fEaX_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. <ins>Install necessary components</ins>\n",
        "\n",
        "- Install Anthropic Libraries <sup><ins>1</ins></sup>\n",
        "- Import Anthropic\n",
        "\n",
        "#### Explore Anthropic SDK\n",
        "\n",
        "- <sup><ins>1</ins></sup> : [Anthropic SDK](https://docs.anthropic.com/en/api/client-sdks)\n",
        "\n",
        "   - <sub>[![Anthropic Claude](https://img.shields.io/badge/Anthropic-Claude-000000?logo=anthropic&logoColor=white)](https://www.anthropic.com) <sup>|</sup> [![Anthropic Claude API](https://img.shields.io/badge/Anthropic_API-Platform_Keys_(üí≥üîê)-000000?logo=anthropic&logoColor=white)](https://console.anthropic.com/api-keys) <sup>|</sup> [![Anthropic API Reference](https://img.shields.io/badge/Anthropic_API-Reference-000000?logo=anthropic&logoColor=white)](https://console.anthropic.com/docs/api-reference) <sup>|</sup> [![GitHub](https://img.shields.io/badge/Anthropic-GitHub-181717?logo=github&logoColor=white)](https://github.com/anthropic) <sup>|</sup> [![PyPI](https://img.shields.io/badge/Anthropic-PyPI-3775A9?logo=pypi&logoColor=white)](https://pypi.org/project/anthropic/)</sub>"
      ],
      "metadata": {
        "id": "xoYevZJPaO7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--HsA5LXTQ_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143ce257-4ddb-4c0f-f53a-5ca77c04de51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Downloading anthropic-0.33.0-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m866.9/866.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.33.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic"
      ],
      "metadata": {
        "id": "1BI4HTKkTeNQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "T7gVaxBvlu3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. <ins>Instantiate an Antropic client passing in your API Key.</ins>\n",
        "\n",
        "#### Anthropic Client\n",
        "1. [Create an API Key-NightFallAI](https://www.nightfall.ai/ai-security-101/anthropic-claude-api-key)\n",
        "\n",
        "2. Click the \"key\" icon to the left to the \"secrets\" dialog box\n",
        "3. Select \"+ Add new secret\"\n",
        "4. Set Name to `'ANTHROPIC_API_KEY'` and paste your newly created *OpenAI API Key* into `'Value'` <sup><ins>2</ins></sup>\n",
        "5. Make sure \"Notebook access\" is on (check mark will show up to the right if it is on.\n",
        "\n",
        "- <sup><ins>2</ins></sup> : [Anthropic Claude API Key: The Essential Guide](https://platform.openai.com/docs/overview)\n",
        "\n",
        "#### Google CoLab Secrets\n",
        "\n",
        "- Configure your code by storing environment variables, file paths, or keys.\n",
        "- Values stored here are private, visible only to you and the notebooks that you select.\n",
        "- Secret name cannot contain spaces; use underscores, all caps.\n",
        "- `userdata` import is relabeled `as secrets` for clarity of use."
      ],
      "metadata": {
        "id": "odmjGQ-FaiHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up Anthropic client\n",
        "\n",
        "## Import CoLabs User Secrets\n",
        "from google.colab import userdata as secrets\n",
        "\n",
        "## Define Anthropic Client\n",
        "client = anthropic.Anthropic(\n",
        "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    api_key=secrets.get('IBM_ANTHROPIC_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "CnKXv_RFUj03"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "eCsHVBNoEQ7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] Success: Key Loaded (2024-08-09)"
      ],
      "metadata": {
        "id": "NFgfX7JXRPGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. <ins>Reusable function using gpt-4o-mini model for completions.</ins>\n",
        "\n",
        "- Go to the OpenAI website\n",
        "    - Check models that are available:<br>\n",
        "      ***Currently**\n",
        "        - .\n",
        "        - .\n",
        "    - Change the model <sup><ins>3</ins></sup>\n",
        "    - Evaluate the different responses per model.\n",
        "\n",
        "- <sup><ins>3</ins></sup> : [OpenAI Models](https://platform.openai.com/docs/models)"
      ],
      "metadata": {
        "id": "2S6giTDNd1-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: Orginal"
      ],
      "metadata": {
        "id": "4TAJT1DxqmHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Anthropic Message API/Docs\n",
        "\n",
        "> Our models are trained to operate on alternating user and assistant\n",
        "conversational turns. When creating a new Message, you specify the prior\n",
        "conversational turns with the messages parameter, and the model then generates\n",
        "the next Message in the conversation.\n",
        "\n",
        "> Each input message must be an object with a role and content. You can\n",
        "specify a single user-role message, or you can include multiple user and\n",
        "assistant messages. The first message must always use the user role.\n",
        "\n",
        "> If the final message uses the assistant role, the response content will\n",
        "continue immediately from the content in that message. This can be used to\n",
        "constrain part of the model's response.\n",
        "\n",
        "Example with a single user message:\n",
        "\n",
        "        json \\[{ \"role\": \"user\", \"content\": \"Hello, Claude\" }\\]\n",
        "\n",
        "Example with multiple conversational turns:\n",
        "\n",
        "        json \\[{ \"role\": \"user\", \"content\": \"Hello there.\" }, { \"role\": \"assistant\", \"content\": \"Hi, I'm Claude. How can I help you?\" }, { \"role\": \"user\", \"content\": \"Can you explain LLMs in plain English?\" }\\]\n",
        "\n",
        "Example with a partially-filled response from Claude:\n",
        "\n",
        "        json \\[{\"role\": \"user\",\"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"}, { \"role\": \"assistant\", \"content\": \"The best answer is (\" }\\]\n",
        "\n",
        "> Each input message content may be either a single string or an array of\n",
        "content blocks, where each block has a specific type. Using a string for\n",
        "content is shorthand for an array of one content block of type \"text\". The\n",
        "following input messages are equivalent:\n",
        "\n",
        "        json { \"role\": \"user\", \"content\": \"Hello, Claude\" }\n",
        "\n",
        "        json { \"role\": \"user\", \"content\": \\[{ \"type\": \"text\", \"text\": \"Hello, Claude\" }\\] }\n",
        "\n",
        "> Starting with Claude 3 models, you can also send image content blocks:\n",
        "\n",
        "              json {\"role\": \"user\", \"content\": \\[{\"type\": \"image\",\"source\": {\"type\": \"base64\",\"media\\_type\": \"image/jpeg\",\"data\": \"/9j/4AAQSkZJRg...\"}}, { \"type\": \"text\", \"text\": \"What is in this image?\" }\\]}\n",
        "\n",
        "> We currently support the base64 source type for images, and the image/jpeg,\n",
        "image/png, image/gif, and image/webp media types. See examples for more input examples.\n",
        "\n",
        "> Note that if you want to include a system prompt, you can use\n",
        "the top-level system parameter ‚Äî there is no \"system\" role for input\n",
        "messages in the Messages API."
      ],
      "metadata": {
        "id": "Apj_fuPxVfo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oW16VMoISjSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, user_message, role_prompting, role_user=\"user\", token_max=1024):\n",
        "    \"\"\"Generates text using the Anthropic API.\n",
        "\n",
        "    Args:\n",
        "        model: The Anthropic model to use.\n",
        "        user_message: The message to send to the API.\n",
        "        role_prompting: The system parameter to set Claude‚Äôs role.\n",
        "        role_user: The role of the user sending the message.\n",
        "        token_max: The maximum number of tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        The response from the Anthropic API.\n",
        "    \"\"\"\n",
        "    response = client.messages.create(\n",
        "        model=model,\n",
        "        max_tokens=token_max,\n",
        "        system=role_prompting, # <-- role prompt\n",
        "        messages=[\n",
        "            {\"role\": role_user,\n",
        "             \"content\": \"Hi there ...\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Hi I am Claude and I will\"},\n",
        "            {\"role\": role_user,\n",
        "             \"content\": user_message},\n",
        "        ]\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "lHrcb0a8TjjN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUWj_S3xXtGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function: Refactored\n",
        "\n",
        "- Atomic single principle functions.\n",
        "- Cleaner Code\n",
        "- Modular"
      ],
      "metadata": {
        "id": "rA3KqwJWqqEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "ANTHROPIC_MODEL = \"claude-3-5-sonnet-20240620\"\n",
        "user_instruction = \"Once upon a time in a land far, far away, there was a\""
      ],
      "metadata": {
        "id": "Now10YIyrXeg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Call the OpenAPI\n",
        "# 3. Generate the Output\n",
        "\n",
        "\n",
        "# 2.\n",
        "def call_anthropic_api(user_instruction,\n",
        "                       system_role,\n",
        "                       model=\"claude-3-5-sonnet-20240620\"):\n",
        "    \"\"\"Calls the Anthropic API and returns the response.\n",
        "\n",
        "        Args:\n",
        "        user_instruction: The message to send to the API.\n",
        "        system_role: The system parameter to set Claude‚Äôs role.\n",
        "        model: The Anthropic model to use, defaults to ANTHROPIC_MODEL .\n",
        "\n",
        "    Returns:\n",
        "        The response from the Anthropic API.\n",
        "\n",
        "    \"\"\"\n",
        "    response = generate_text(model, user_instruction, system_role)\n",
        "    return response\n",
        "\n",
        "# 3.\n",
        "def generate_output(user_instruction, system_role = \"You are a helpful assistant.\",  model = ANTHROPIC_MODEL):\n",
        "    \"\"\"Generates ouput, based on the user's instruction.\n",
        "\n",
        "    Args:\n",
        "        user_instruction: The message to send to the API.\n",
        "        system_role: The system parameter to set Claude‚Äôs role.\n",
        "        model: The Anthropic model to use, defaults to ANTHROPIC_MODEL .\n",
        "\n",
        "    Returns:\n",
        "        The response's content, the output, from the Anthropic API.\n",
        "\n",
        "    \"\"\"\n",
        "    messages = call_anthropic_api(user_instruction).content\n",
        "    return call_openai_api(messages)"
      ],
      "metadata": {
        "id": "0C6S_x6Sp0GX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "7L29p6G9rjmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. <ins>Example</ins>\n",
        "- **`Task`**: Write a fairy tale\n",
        "- Steps\n",
        "    1. Assign prompt\n",
        "    2. Generate\n",
        "        - a: Original Function: Generate Text\n",
        "        - b: Refactored Function: Generate Output\n",
        "    3. Display Output"
      ],
      "metadata": {
        "id": "5nJTCSVOet8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Example prompt\n",
        "message_content = user_message\n",
        "\n",
        "# 2.a. Original: Generate text\n",
        "generated_out = generate_text(message_context)\n",
        "\n",
        "# 2.b. Refactored: Generate Ouput\n",
        "# generated_text = generate_output(message_content)\n",
        "\n",
        "# Display the output\n",
        "print(\"Prompt:\", message_content)\n",
        "print(\"--- --- --- \\n --- --- ---\")\n",
        "print(\"Generated Text:\", generated_out)\n"
      ],
      "metadata": {
        "id": "FUJxYWq1TppO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "SP5S96pZEUBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. <ins>Create an interactive prompt.</ins>\n",
        "1. Start a story like, \"Once upon a time there was a princess fighting for her\" HINT: leave it hanging so the model knows to start generating\n",
        "2. Ask, \"How do I bake a cake?\""
      ],
      "metadata": {
        "id": "LKw5xIe4e25E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import IPython widgets for interactive input\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create a text box for user input\n",
        "prompt_box = widgets.Textarea(\n",
        "    value='Enter your prompt here...',\n",
        "    placeholder='Type something...',\n",
        "    description='Prompt:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Create a button to generate text\n",
        "button = widgets.Button(description=\"Generate Text\")\n",
        "\n",
        "# Function to handle button click\n",
        "def on_button_click(b):\n",
        "    prompt = prompt_box.value\n",
        "    generated_text = generate_text(prompt)\n",
        "    print(\"Prompt:\", prompt)\n",
        "    print(\"Generated Text:\", generated_text)\n",
        "\n",
        "# Attach the function to the button click event\n",
        "button.on_click(on_button_click)\n",
        "\n",
        "# Display the text box and button\n",
        "display(prompt_box, button)\n"
      ],
      "metadata": {
        "id": "JWxgJ17pTts5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "e6JqCHkpEWcm"
      }
    }
  ]
}