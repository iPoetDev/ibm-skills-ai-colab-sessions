{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/final-project/final-project/IBMSkillsBuild_ANSWER_AI_CreditCardFraudDetection_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead4329e",
      "metadata": {
        "id": "ead4329e"
      },
      "source": [
        "![](https://github.com/iPoetDev/ibm-skills-ai-colab-sessions/blob/final-project/final-project/assets/img/skillup-logo.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c25c7041",
      "metadata": {
        "id": "c25c7041"
      },
      "source": [
        "# **FINAL PROJECT**: IBM Programme for Artifical Intelligence 2024:<br> **Credit Card Fraud Detection** <sup><small>Graded, Assessed</small></sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ### OBJECTIVE: To apply the theory, utilise the hands-on live techical sessions examples in the implemenation of:<br>\n",
        "> ## 1Ô∏è‚É£ Credit Card Fraud Detection\n",
        ">> *  Use python libraries and frameworks\n",
        ">> *  Apply a workflow breakdown structure to the project, step by step.\n",
        ">> *  Gather and discet a kaggle dataset, as provided.\n",
        ">> *  Create an orginal authentic solution to the problem\n",
        "\n",
        "> <hr>\n",
        "\n",
        "- **URL**: <sup><b>eLearning, Login</b></sup>\n",
        "- **Share**: <sup><b>eLearning, Login</b></sup>\n",
        "- **Box.com**: []() <sup><b>eLearning, Login</b></sup>\n",
        "- **Assessment**:[]() <sup><b>eLearning, Login</b></sup>\n",
        "- **Source**: Notebook:\n",
        "\n",
        "**AUDIENCE**\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "> <hr>\n",
        "\n",
        "# Table of Contents\n",
        "\n",
        "- [1. Project Management]()\n",
        "- [2. Dataset]()\n",
        "- [3. Methods & Approaches]()\n",
        "- [4. Workflow]()\n",
        "- [5. Solution]()\n",
        "- [6. Findings]()"
      ],
      "metadata": {
        "id": "mfoxl70UGQZH"
      },
      "id": "mfoxl70UGQZH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **<ins>PROJECT MANAGE</ins>**\n",
        "\n",
        "> ### Using GitHub Projects gives a porfilio and developmental space for processing this notebook. <br>\n",
        "> ### Summary highlights will be addessed in the `./üìÅfinal-project/`';s [README.md]()\n",
        "\n",
        "\n",
        "- This project is planned and controlled by a [GitHub Project: PROJECT: IBM Programme for Artificial Intelligence - Credit Card Fraud ](https://github.com/users/iPoetDev/projects/22)\n",
        "\n",
        "  - Project control and iterative/agile workflows to show case the work items and plan for solving final Project for the Programme for Artificial Intelligence 2024.\n",
        "  - Uses:\n",
        "    - Backlog\n",
        "    - Kanband Priority Board\n",
        "    - Roadmap\n",
        "\n",
        "### STAGES\n",
        "\n",
        "- DEFINE\n",
        "- IDENTIFY\n",
        "- GATHER\n",
        "- MANIPULATE\n",
        "- SELECT\n",
        "- TRAIN\n",
        "- VALIDATE\n",
        "- IMPROVE\n",
        "\n",
        "\n",
        "#### Key\n",
        "\n",
        "Key |  Use | Project Use Case\n",
        "---: | ---: | ---\n",
        "‚úÖ | In Scope | For submission\n",
        "‚òëÔ∏è | Provided | Item is resources\n",
        "‚Ü™Ô∏è | Skip | Step is not necessary\n",
        "‚ùì| TBC | To be confirmed\n",
        "üõë | Not In scope | Future development\n",
        "\n",
        "### STEPS: To Solution <sup>Assessable</sup>\n",
        "\n",
        "- [ ]  [1] [<ins> Problem Identification</ins>](https://github.com/users/iPoetDev/projects/22/views/1?pane=issue&itemId=72909228) ‚úÖ\n",
        "  - [ ] Define the task\n",
        "  - [ ] Identify the goals\n",
        "  - [ ] Understand the requirements<br><br>\n",
        "- [ ]  [2] [<ins> Data Collection</ins>](https://github.com/users/iPoetDev/projects/22/views/1?pane=issue&itemId=72909298) ‚úÖ\n",
        "  - [ ] Gather Relevant Data ‚òëÔ∏è\n",
        "  - [ ] Ensure Data diversity\n",
        "  - [ ] Prioritize quality sources <br><br>\n",
        "- [ ]  [3] [<ins> Data Processing</ins> ‚úÖ](https://github.com/users/iPoetDev/projects/22?pane=issue&itemId=72909353)\n",
        "  - [ ] Clean the data\n",
        "  - [ ] Organize information\n",
        "  - [ ] Format for analysis <br><br>\n",
        "- [ ]  [4] [<ins> Algorithm Selection</ins> ‚úÖ](https://github.com/users/iPoetDev/projects/22#)\n",
        "  - [ ] Choose appropriate models\n",
        "  - [ ] Consider task complexity\n",
        "  - [ ] Evaluate Efficiency <br><br>\n",
        "- [ ]  [5] [<ins> Model Training</ins> ‚úÖ](https://github.com/users/iPoetDev/projects/22?pane=issue&itemId=72916346)\n",
        "  - [ ] Feed data into model\n",
        "  - [ ] Adjust Parameters\n",
        "  - [ ] Optimize performance <br><br>\n",
        "- [ ]  [6] [<ins>Testing and Validation</ins> ‚úÖ](https://github.com/users/iPoetDev/projects/22?pane=issue&itemId=72916473)\n",
        "  - [ ] Assess model accuracy\n",
        "  - [ ] Cross Validate Results\n",
        "  - [ ] Ensure reliability <br><br>\n",
        "- [ ]  [ 7] [<ins> Iteration and Improvement </ins> ‚úÖ](https://github.com/users/iPoetDev/projects/22?pane=issue&itemId=72917451)\n",
        "  - [ ] Refine algorithms (selection, or logic)\n",
        "  - [ ] Enhance data quality (sourcing, composition)\n",
        "  - [ ] Optimize parameters (weights, biases)\n",
        "\n",
        "> <hr>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NR3dn7YI50i"
      },
      "id": "4NR3dn7YI50i"
    },
    {
      "cell_type": "markdown",
      "id": "daaffd97",
      "metadata": {
        "id": "daaffd97"
      },
      "source": [
        "## 2. [<ins>Dataset</ins>](https://github.com/users/iPoetDev/projects/22/views/1?pane=issue&itemId=72909298)\n",
        "\n",
        "- Source: Kaggle.com\n",
        "- Link: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "lEujkXhCNdAQ"
      },
      "id": "lEujkXhCNdAQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Methods & Approaches\n",
        "\n",
        "-"
      ],
      "metadata": {
        "id": "kyLJToeRNIJq"
      },
      "id": "kyLJToeRNIJq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>"
      ],
      "metadata": {
        "id": "zRNKLs-ZNZ86"
      },
      "id": "zRNKLs-ZNZ86"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. <ins>Workflow</ins>\n",
        "\n",
        "### a. Libraries\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### b. Process Dataset\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### c. Clean Data\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### d. Analyse\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### e. Visualise\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### f. Model Development\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### g. Modul Eval:\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### h. Spliting Dataset\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### i. Evaluate Model"
      ],
      "metadata": {
        "id": "nQuDO_E8L8Vr"
      },
      "id": "nQuDO_E8L8Vr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <hr>\n",
        "> <hr>"
      ],
      "metadata": {
        "id": "34nTdBglNVqE"
      },
      "id": "34nTdBglNVqE"
    },
    {
      "cell_type": "markdown",
      "id": "6795d0c1",
      "metadata": {
        "id": "6795d0c1"
      },
      "source": [
        "## 5. Solution\n",
        "\n",
        "### Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb4d791",
      "metadata": {
        "id": "2eb4d791"
      },
      "outputs": [],
      "source": [
        "# Importing Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4134d12",
      "metadata": {
        "id": "c4134d12"
      },
      "source": [
        "### Import and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b35f75",
      "metadata": {
        "id": "29b35f75"
      },
      "outputs": [],
      "source": [
        "# Read Data into a Dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bd8703",
      "metadata": {
        "id": "f4bd8703"
      },
      "source": [
        "\n",
        "<details><summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Start by importing the pandas library: import pandas as pd\n",
        "    \n",
        "Use the read_csv() function to load the CSV file into a pandas DataFrame. Specify the file path in the parentheses, for example: pd.read_csv(\"file_path.csv\")\n",
        "    \n",
        "Assign the resulting DataFrame to a variable name, for example: data = pd.read_csv(\"file_path.csv\")\n",
        "    \n",
        "Use the head() method on the DataFrame to display the first 10 rows, for example: data.head(10)\n",
        "    \n",
        "Make sure to replace \"file_path.csv\" with the actual file path and name of your CSV file.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d4fe1a9",
      "metadata": {
        "id": "3d4fe1a9"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe00f5bd",
      "metadata": {
        "id": "fe00f5bd"
      },
      "source": [
        "a. Missing Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd10e6f",
      "metadata": {
        "id": "efd10e6f"
      },
      "outputs": [],
      "source": [
        "#Write Your Code Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f377dddf",
      "metadata": {
        "id": "f377dddf"
      },
      "source": [
        "<details><summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Use the DataFrame variable name followed by the isnull() method to create a Boolean DataFrame where True indicates a null value and False indicates a non-null value.\n",
        "\n",
        "Use the sum() method on the Boolean DataFrame to count the number of True values (i.e., the number of null values) in each column.\n",
        "\n",
        "Putting these together, the code would look like this: data.isnull().sum()\n",
        "\n",
        "\n",
        "This code assumes that the pandas DataFrame is named data. If your DataFrame has a different name, replace data with the appropriate variable name.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4516036d",
      "metadata": {
        "id": "4516036d"
      },
      "source": [
        "b. Duplicate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da501911",
      "metadata": {
        "id": "da501911"
      },
      "outputs": [],
      "source": [
        "#Write Your Code Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b028638",
      "metadata": {
        "id": "3b028638"
      },
      "source": [
        "<details><summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Use the DataFrame variable name followed by the duplicated() method to create a Boolean DataFrame where True indicates a duplicate row and False indicates a non-duplicate row.\n",
        "\n",
        "Use the sum() method on the Boolean DataFrame to count the number of True values (i.e., the number of duplicate rows).\n",
        "\n",
        "Putting these together, the code would look like this: data.duplicated().sum()\n",
        "\n",
        "This code assumes that the pandas DataFrame is named data. If your DataFrame has a different name, replace data with the appropriate variable name.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5119181",
      "metadata": {
        "id": "b5119181"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d6331",
      "metadata": {
        "id": "5f9d6331"
      },
      "source": [
        "Question 1: What is the percentage of fraud transactions in the dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc08822c",
      "metadata": {
        "id": "fc08822c"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of fraud transactions\n",
        "\n",
        "# Print the percentage of fraud transactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7446af09",
      "metadata": {
        "id": "7446af09"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "    To calculate the percentage of fraud transactions, you need to count the number of fraud transactions (where 'Class' is 1) and divide it by the total number of transactions in the dataset. Then, multiply the result by 100 to get the percentage.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906ae755",
      "metadata": {
        "id": "906ae755"
      },
      "source": [
        "Question 2: What is the average transaction amount for fraud transactions?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38993dc8",
      "metadata": {
        "id": "38993dc8"
      },
      "outputs": [],
      "source": [
        "# Calculate the average transaction amount for fraud transactions\n",
        "\n",
        "\n",
        "# Print the average transaction amount for fraud transactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d63dff",
      "metadata": {
        "id": "28d63dff"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "    To calculate the average transaction amount for fraud transactions, you need to filter the dataset to get only the fraud transactions (Class = 1) and then calculate the mean of the 'Amount' column for that filtered data.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c947f70",
      "metadata": {
        "id": "4c947f70"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02753134",
      "metadata": {
        "id": "02753134"
      },
      "source": [
        "\n",
        "Question 1: How many fraud transactions are there compared to non-fraud transactions? (Using a bar plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65747ac7",
      "metadata": {
        "id": "65747ac7"
      },
      "outputs": [],
      "source": [
        "# Count the number of fraud and non-fraud transactions\n",
        "\n",
        "# Plot the distribution of fraud transactions compared to non-fraud transactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd4df45",
      "metadata": {
        "id": "bdd4df45"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "    To create a bar plot showing the number of fraud and non-fraud transactions, you need to count the occurrences of each class (fraud and non-fraud) in the 'Class' column and then use a bar plot to represent the counts.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a282afc",
      "metadata": {
        "id": "6a282afc"
      },
      "source": [
        "Question 2: What is the distribution of transaction amounts for fraud transactions? (Using a histogram)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a8b8b2",
      "metadata": {
        "id": "97a8b8b2"
      },
      "outputs": [],
      "source": [
        "# Separate the data for fraud transactions\n",
        "\n",
        "# Plot the distribution of transaction amounts for fraud transactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74ede115",
      "metadata": {
        "id": "74ede115"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "    To visualize the distribution of transaction amounts for fraud transactions, you need to filter the dataset to get only the fraud transactions (Class = 1) and then use a histogram to represent the distribution of 'Amount' values in that filtered data.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e330fde",
      "metadata": {
        "id": "8e330fde"
      },
      "source": [
        "### Model Development & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3199958a",
      "metadata": {
        "id": "3199958a"
      },
      "source": [
        "### Splitting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c16e87f",
      "metadata": {
        "id": "5c16e87f"
      },
      "outputs": [],
      "source": [
        "# Split training and testing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f05b4ea",
      "metadata": {
        "id": "3f05b4ea"
      },
      "source": [
        "<details><summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Once you have this dataset, you can use the scikit-learn library to split the data into training and testing sets using the train_test_split() function.\n",
        "\n",
        "First, you can create a pandas DataFrame X with all columns except the 'Class' column. You can create a pandas Series y with only the 'Class' column.\n",
        "\n",
        "Next, you can use the train_test_split() function to split the data into training and testing sets. You can pass in the X and y variables as arguments, along with the test_size argument to specify the proportion of the dataset that should be allocated to the testing set (in this case, 20%). The random_state argument can also be set to a fixed value so that the same random split is produced every time the code is run.\n",
        "\n",
        "The train_test_split() function returns four variables: X_train, X_test, y_train, and y_test. X_train and y_train represent the training set, while X_test and y_test represent the testing set. You can use these variables to train and evaluate your machine learning models.\n",
        "\n",
        "Note that it's important to split the data into training and testing sets to avoid overfitting and to evaluate the performance of your models on unseen data.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8721f8dc",
      "metadata": {
        "id": "8721f8dc"
      },
      "source": [
        "### Modeling & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496d2812",
      "metadata": {
        "id": "496d2812"
      },
      "outputs": [],
      "source": [
        "#Write Your Code Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a9d4ce",
      "metadata": {
        "id": "97a9d4ce"
      },
      "source": [
        "<details><summary><b>Click Here for the Hint</b></summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "You need to have imported the necessary libraries and classes, such as the RandomForestClassifier class from scikit-learn and the classification_report() and accuracy_score() functions from the sklearn.metrics module.\n",
        "\n",
        "Once you have done this, you can create an instance of the RandomForestClassifier class, setting the max_depth hyperparameter to 150 and the random_state hyperparameter to 42. You can then train the model on the training data using the .fit() method.\n",
        "\n",
        "Next, you can use the trained model to make predictions on the testing data using the .predict() method. You can store these predictions in a variable called y_pred.\n",
        "\n",
        "Then, you can use the classification_report() function to print out a summary of the model's performance on the testing data. This will include metrics such as precision, recall, and F1 score for each class (in this case, whether a credit card transaction is fraud or not). You can also use the accuracy_score() function to calculate and print the overall accuracy of the model on the testing data.\n",
        "\n",
        "Finally, you can print out the accuracy of the model in percentage form, using the *100 operator to multiply the accuracy score by 100.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}