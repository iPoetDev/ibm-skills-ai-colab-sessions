# **<ins>ibm-skills-ai-colab-sessions</ins>**
> ## IBM Skills Build AI Fundamentals - Colab - Sessions

### **Objectives**
<center style=font-size:18px><strong><ins>A. Portfolio focused Project Based Learning</ins>

<ins>B. Self Directed Configuration of VSCode and Python Locally</ins>
</strong></center>

---
>  ...
---

## **<ins>A. Portfolio focused Project Based Learning</ins>**

*Artefacts from Live Technical Sessions in the form of*:

- `Session 1`: Python Fundamentals (for beginners and new to Python). **(2024.06.19)**
  - [<ins>`üñáÔ∏è Session1.ipnyb`</ins>](./notebooks-labs/Session1.ipynb "Folder: notebooks-labs: Session 1: Python Fundamentals"): <br>
    **CoLab** Run -> [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10ZTbzzrTTrYpzu4xFcN88gV_Rai4Y-Rj?usp=sharing "Session 1: Google Colab: Session2_Regression_Clustering_Classification_Recommender.ipnyb"):
    - NB: *Was familar with Python Fundamentals from previous software engineering efforts and courses.*
      - i) Lists, Tuples, and Dictionaries
      - ii) Basic Python Operations
      - iii) Flow Control Structoures
      - iv) Handling errors
      - v) Functions
    - Recommended Activities
      1.   Code with Mosh [Complete Python Mastery ](https://codewithmosh.com/p/python-programming-course-beginners)
      2.   Practice Katas, for example, [Code Wars](https://www.codewars.com/), [CodeSignal](https://learn.codesignal.com/)
- `Session 2`: Machine Learning Models and Methodologies Fundamentals. **(2024.07.02)**
  - [<ins>`üñáÔ∏è Session2.ipnyb`</ins>](./notebooks-labs/Session2.ipynb "Folder: notebooks-labs: Session 2: Machine Learning Fundamentals") <br>
      **CoLab** Run -> [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1FW5-OGD2jegulfkF8afRptkZ3cEakL--?usp=sharing "Session 2: Google Colab: Session2_Regression_Clustering_Classification_Recommender.ipnyb"):
    - i) Regressions
    - ii) Classifications 
    - iii) Clustering 
    - iv) Recommender Systems 
- `Session 3`: Generative AI Lab **(2024.07.16)** 
  - [<ins>`üñáÔ∏è  Session3_VAE.ipnyb`</ins>](./notebooks-labs/Session3_VAE.ipynb "Folder: notebooks-labs: Session 3: Assumed GitHub as Host, Use Google Colabl as Host"): <br>
    **CoLab** Run -> [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1eD7pRKmhVFl0nfwzsoIy9RTtoPMVkZPW?usp=sharing "Session 3: Google Colab: Session3_VAE.ipynb")
    - i) Load Datasets
    - ii) Encoders
    - iii) VAE Sampling
    - iv) Decoders
    - v) VAE Model
    - vi) VAE Loss
    - vii) Model Training
    - viii) Display Images (func) 
    <br><br>
  - [<ins>`üñáÔ∏è Session3_Transformers.ipnyb`</ins>](./notebooks-labs/Session3_FineTuning_BERTandGPT.ipynb "Folder: notebooks-labs: Session 3: Assumed GitHub as Host, Use Google Colabl as Host"): <br> 
    **CoLab** Run -> [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19YcHhGy__BdZp3iDGeiytA0ZfCrfiPCY?usp=sharing "Session 3: Google Colab: Session3_VAE.ipynb")
    - i) Setups/Imports
    - ii) Load Datasets
    - iii) Load Transformer Model (BERT)
    - iv) Training Params
    - v) Trainer
    - vi) Model Evaluation
    - vii) Predictions
    <br><br>

---
>  ...
---


## **<ins>B. Machine Learning Methods & Approaches</ins>** 

- `Session 2`: [Unsupervised Learning Models](./Sessions.md#1-unsupervised-learning).
- `Session 3`:
    - 3.1 [GenAI: VAE](./Sessions.md#2-generative-ai-vae-session-3)
    - 3.2 [GenAI: Tuning Transformers](./Sessions.md#3-generative-ai-tuning-transformers-session-3)

<center><small>Use the Jumpto buttons to launch Google Colab per Sessions' cell</small></center>

> <hr>

### <ins>Unsupervised Learning</ins>

[![Session2](https://img.shields.io/badge/Session2--Notebook-Launch-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb "Open Session 2.ipynb on colab.google.com")

> #### **Objective**: *Understand the theory and hands-on implementation of: <br>  1Ô∏è‚É£ [Regression](./Sessions.md#1Ô∏è‚É£-regression), <br> 2Ô∏è‚É£ [Classification](./Sessions.md#2Ô∏è‚É£-classification), <br> 3Ô∏è‚É£ [Clustering](./Sessions.md#3Ô∏è‚É£-clustering)* and <br>  *4Ô∏è‚É£ [Recommender Systems](./Sessions.md#4Ô∏è‚É£-recommender-systems)*.


### *1Ô∏è‚É£ Regression*

[![Session2 Regressions](https://img.shields.io/badge/Session2--Regressions-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=DbTvKgpCjf6w "Open Session 2.ipynb on colab.google.com at Regression")

#### <ins>NumPy</ins><sup><em>A</em></sup>
>  NumPy, short for "Numerical Python," is a powerful library used in Python programming for numerical and scientific computing. 

NumPy like a supercharged version of Python's built-in list data structure, designed to handle large amounts of data more efficiently.

[![NumPy](https://img.shields.io/badge/NumPy-Website-1f77b4?color=1f77b4&logo=numpy&logoColor=4d77cf)](https://numpy.org/ "NumPy: Website") <sup>|</sup> [![NumPy](https://img.shields.io/badge/NumPy-GitHub-1f77b4?color=1f77b4&logo=numpy&logoColor=4d77cf)](https://github.com/numpy/numpy "NumPy: GitHub") <sup>|</sup> [![NumPy](https://img.shields.io/badge/NumPy-PyPi-1f77b4?color=1f77b4&logo=numpy&logoColor=4d77cf)](https://pypi.org/project/numpy/ "NumPy: üêç PyPi")

#### <ins>Matplotlib</ins><sup><em>B</em></sup>

> Matplotlib is a powerful library in Python used for creating visualizations, such as graphs and charts. 

MatplotLibs is particularly useful for data scientists, engineers, and anyone who needs to visualize data to understand and communicate trends, patterns, and insights

[![Matplotlib](https://img.shields.io/badge/Matplotlib-Website-1f77b4?color=1f77b4&logo=matplotlib&logoColor=white)](https://matplotlib.org/stable/ "MatplotLib: Website") <sup>|</sup> [![Matplotlib](https://img.shields.io/badge/Matplotlib-GitHub-1f77b4?color=1f77b4&logo=matplotlib&logoColor=white)](https://github.com/matplotlib/matplotlib "MatplotLib: GitHub") <sup>|</sup> [![Matplotlib](https://img.shields.io/badge/Matplotlib-PyPi-1f77b4?color=1f77b4&logo=matplotlib&logoColor=white)](https://pypi.org/project/matplotlib/ "MatplotLib: üêç PyPi")

#### Linear Regression

> ...

[![Session2 Classification](https://img.shields.io/badge/Session2--Logistic%20Regression-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=ipSw8bcdxILh "Open Session 2.ipynb on colab.google.com at Logistic Regression")

> <hr>

### *2Ô∏è‚É£ Classification*

[![Session2 Classification](https://img.shields.io/badge/Session2--Classification-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=KAYQ-r1fjwD3  "Open Session 2.ipynb on colab.google.com at Classification")

#### <ins>SciKit_Learn</ins>

> Scikit-learn is a popular Python library for machine learning, offering simple and efficient tools for data analysis and modeling

SciKit_Learn (`sklearn`) provides a wide range of algorithms for classification, regression, clustering, and dimensionality reduction. 
- It integrates well with other scientific libraries like NumPy and pandas
- As such, makes it easy to build and evaluate machine learning models. 
- Is widely used for its 
    - ease of use, 
    - comprehensive documentation, and 
    - versatility in handling different machine learning tasks.

 
[![SciKit Learn](https://img.shields.io/badge/SciKit-Website-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/index.html  "SciKit-Learn.org Website") <sup> | </sup> [![SciKit Learn](https://img.shields.io/badge/SciKit-GitHub-3499cd?logo=scikit-learn&logoColor=f89939)](https://github.com/scikit-learn/scikit-learn  "SciKit-Learn.org GitHub") <sup> | </sup> [![SciKit Learn](https://img.shields.io/badge/SciKit-PyPi-3499cd?logo=scikit-learn&logoColor=f89939)](https://pypi.org/project/scikit-learn/  "SciKit-Learn.org üêç PyPi")


#### <ins>Logistic Regression</ins>

> Logistic Regression models, as a type of linear models, are used as a common workflow in classification tasks (like binary classification) where you want to estimate the likelihood of a data point belonging to different categories.

[![Session2 Classification](https://img.shields.io/badge/Session2--Logistic%20Regression-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=ipSw8bcdxILh "Open Session 2.ipynb on colab.google.com at Logistic Regression")

> <hr>

### *3Ô∏è‚É£ Clustering*

[![Session2 Clustering](https://img.shields.io/badge/Session2--Clustering-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=mz4O8oP4j5xM "Open Session 2.ipynb on colab.google.com at Clustering")



1. K-Means Clustering
2. Hierarchical Clustering
3. DBSCAN

> Are just 3 of the 26 algorithms from [`sklearn.cluster`](https://scikit-learn.org/stable/api/sklearn.cluster.html "scikit-learn.org: Popular unsupervised clustering algorithms."), and the rest are out of scope for this purpose.

#### <ins>K-Means Clustering</ins>

> K-Means is an unsupervised machine learning algorithm that partitions a dataset into k distinct clusters based on similarities, aiming to minimize the sum of squared distances between data points and their assigned cluster centroids

It minimizes within-cluster variances (squared Euclidean distances), facilitating partitioning by mean rather than Euclidean distances.

[![KMeans API](https://img.shields.io/badge/SciKit-KMeans%20API-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/clustering.html#k-means "SciKit-Learn: sklearn.cluster API documentation: KMeans") <sup>|</sup> [![KMeans User Guide](https://img.shields.io/badge/SciKit-KMeans%20%20GUIDE-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/clustering.html#k-means "SciKit-Learn: sklearn.cluster User Guide: KMeans")

#### <ins>Hierarchical Clustering</ins> 

[![Session2 Clustering](https://img.shields.io/badge/Session2--Clustering-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=fhkWdnYODOko  "Open Session 2.ipynb on colab.google.com at Hierarchical Clustering")

> Hierarchical Clustering (a la Agglomerative Clustering) is an unsupervised machine learning algorithm that groups unlabeled data points into a hierarchy of clusters based on their similarity. An analytical method that seeks to build a hierarchy of clusters by either merging or splitting them based on data observations.

It builds a cluster hierarchy in the form of a tree-like structure called a dendrogram, where each merge or split is represented by a node
- Agglomerative (Bottom-up) - Starting small, think of this as starting with one feature as its own group
- Divisive (Top-down) - Starting big, think of this as starting with the whole box of features as one big group

[![Hierarchical/Agglomerative API](https://img.shields.io/badge/SciKit-Agglormerative%20API-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering "SciKit-Learn: sklearn.cluster API documentation: Hierarchical/Agglomerative") <sup>|</sup> [![Heirachical User Guide](https://img.shields.io/badge/SciKit-Hierarchical%20%20GUIDE-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering "SciKit-Learn: sklearn.cluster User Guide: Hierarchical/Agglomerative")

#### <ins>DBSCAN</ins>

[![Session2 Clustering](https://img.shields.io/badge/Session2--Clustering-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=g746XDACEXTw "Open Session 2.ipynb on colab.google.com at DBSCAN")

> DBSCAN is an unsupervised clustering algorithm that groups together closely packed data points based on their density, while identifying points in low-density regions as outliers or noise.

- DBSCAN is known as Density-Based Spatial Clustering of Applications with Noise.

It operates by defining clusters as areas where a minimum number of points (minPts) exist within a specified radius (epsilon) around each point, allowing it to detect clusters of arbitrary shapes and effectively handle noise in datasets

[![DBSCAN Clustering API](https://img.shields.io/badge/SciKit-DBSCAN%20API-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html "SciKit-Learn: sklearn.cluster API documentation: DBSCAN") <sup>|</sup> [![DBSCAN User Guide](https://img.shields.io/badge/SciKit-DBSCAN%20GUIDE-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/clustering.html#dbscan "SciKit-Learn: sklearn.cluster User Guide: DBSCAN")

> <hr>

### *4Ô∏è‚É£ Recommender Systems*

[![Session2 Recommender](https://img.shields.io/badge/Session2--Recommender-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session2.ipynb#scrollTo=1VARKLrgkBcu "Open Session 2.ipynb on colab.google.com at Recommender Systems")


> Recommender systems are a type of information filtering system that predict the "rating" or "preference" a user would give to an item. They help users discover items they might like but haven't encountered yet. The algorthmic steps are somewhat as follows:<br><br>
>   &nbsp;&nbsp;i.&nbsp;&nbsp; Idenitify a target to compare.<br>
>   &nbsp;&nbsp;ii.&nbsp; Find similar targets. <br>
>   &nbsp;&nbsp;iii. Calculate an average value for similar targets. <br>
>   &nbsp;&nbsp;iv.&nbsp; Sort the high ranking values for recommendations. <br>
>   &nbsp;&nbsp;v.&nbsp;&nbsp;  Display the recommendation. <br>

#### <ins>Pandas</ins>

>  Pandas aims to be the fundamental high-level building block for doing practical, real world data analysis in Python; designed to make working with "relational" or "labeled" data both easy and intuitive

- Pandas, as a python package, has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language, via fast, flexible, and expressive data structures. It is already well on its way towards this goal.

[![Pandas](https://img.shields.io/badge/Pandas-Website-1f77b4?color=1f77b4&logo=pandas&logoColor=white)](https://pandas.pydata.org/ "Pandas: Website") <sup>|</sup> [![NumPy](https://img.shields.io/badge/Pandas-GitHub-1f77b4?color=1f77b4&logo=pandas&logoColor=white)](https://github.com/pandas-dev/pandas "Pandas: GitHub") <sup>|</sup> [![Pandas](https://img.shields.io/badge/Pandas-PyPi-1f77b4?color=1f77b4&logo=pandas&logoColor=white)](https://pypi.org/project/pandas/ "Pandas: üêç PyPi")

#### <ins>Cosine Similarity</ins> (`SKLearn.metrics`)

> SKLearn.metrics is part of 3 APIs used for evaluating the quality of a model's predicitions; specifically implementing functions assessing prediction error for targeted purposes.

- Score functions, performance metrics, pairwise metrics and distance computations.

> SciKit's Metric Pairwise sub module implements utilities to evaluate pairwise distances or affinity of sets of samples.

- Pairwise metrics is involved with subset of data transformations [Pairwise metrics, affinities and Kernels](https://scikit-learn.org/stable/modules/metrics.html#metrics), specifically covering transforming feature spaces into affinity spaces.

- [`Cosine Similarity`](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity "scikit-learn.org: User Guide: Metrics | Pairwise submodules") is a popular choice for computing the similarity of documents represented as tf-idf vectors.
    - `tf-idf` vectors:
        - TF-IDF stands for: Term Frequency-Inverse Document Frequency.
        - They represent text documents as numerical vectors, where each dimension corresponds to a unique word 
   - called so as Euclidean (L2) normalization projects the vectors onto the unit sphere.
        - As their dot product is then the cosine of the angle between the points denoted by the vectors.
   - accepts `scipy.sparse` matrices.
   - computes the L2-normalized dot product of vectors. That is, if `\(x\)` and `\(y\)` are row vectors, their cosine similarity `\(k\)` as follows for equation display:

##### Equation Display

The following equation represents the function `\( k(x, y) \`):

<center><pre>$k(x, y) = \frac{x y^\top}{\|x\| \|y\|}$</pre></center>

[![Pairwise Metrics](https://img.shields.io/badge/SciKit-Metrics--PairWise%20Cosine%20Kernel-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity "SciKit-Learn: sklearn.metrics.pairwise API documentation: Cosine Kernel/Similarity") <sup>|</sup> [![Cosine Kernel User Guide](https://img.shields.io/badge/SciKit-Metrics--Cosine%20Kernel%20GUIDE-3499cd?logo=scikit-learn&logoColor=f89939)](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity "SciKit-Learn: sklearn.metrics.pairwise User Guide: Cosine Kernel/Similarity")
<br><br>
> <hr>
> <hr>
<br><br>

### <ins>Generative AI `Session 3`</ins>

These sessions needs to be run on <small>[![GoogleColab](https://img.shields.io/badge/Google-CoLab-0e80c1?logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/ "Free Compute Credits across CPU/GPU")</small> if local system compute are not configured or specified for GPU loads.

> #### **Objective**: *Exploring and implementing basic generative models as well as pre-trained foundational models; along with fine tuning these models for specific tasks*: <br><br> *1Ô∏è‚É£ Generative AI: Variational Autoencoders (VAE) (3.1)*<br> *2Ô∏è‚É£ Generative AI: Fine Tuning Transformers (3.2)*

### 1Ô∏è‚É£ <ins>Generative AI: VAE: `Session 3.1`</ins>

[![Session 3.1 VAE](https://img.shields.io/badge/Session3.1%20GenAI%20VAE-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session3_VAE.ipynb "Open Session3_VAE.ipynb on colab.google.com")

> VAE is an unsupervised learning technique where the machine is using and analyzing unlabeled data sets. With this method, the model can learn patterns in the data and learn how to reconstruct the inputs as its outputs after significantly downsizing it.

- Autoencoders have four main layers: `encoder`, `bottleneck`, `decoder`, and the `reconstruction loss`.
    - The `encoder` is the given input with reduced dimensionality.   
    - The `bottleneck` is the compressed representation of the encoded data.
    - The `decoder` is the reconstructed version of the original output.
    -  The `reconstruction` loss is the difference between the original output and the reconstructed output.

<br>
<center><pre>Input ‚û°Ô∏è Encoder ‚û°Ô∏è Bottleneck ‚û°Ô∏è Decoder ‚û°Ô∏è Ouput</pre></center>

#### <ins>TensorFlow</ins>
> TensorFlow is an end-to-end open source platform for machine learning and it is easy to create ML models that can run in any environment. 

- It has a comprehensive, flexible ecosystem of tools, libraries, and community resources to  build and deploy ML-powered applications.
    - Lite lirbaries for mobile and edge devices
    - Browser libraries
    - ML models & datasets
    - Developer tools for model evaluation, performance optimisation and productising ML workflows.

[![TensorFlow](https://img.shields.io/badge/TensorFlow-Website-FF6F00?logo=tensorflow&logoColor=white)](https://github.com/tensorflow/tensorflow "Tensorflow: Tensorflow.org") <sup>|</sup> [![TensorFlow](https://img.shields.io/badge/TensorFlow-Guide-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/guide/basics "Tensorflow: High Level Guide") <sup>|</sup> [![TensorFlow](https://img.shields.io/badge/TensorFlow-GitHub-FF6F00?logo=tensorflow&logoColor=white)](https://github.com/tensorflow/tensorflow "TensorFlow: GitHub.com") <sup>|</sup> [![TensorFlow](https://img.shields.io/badge/TensorFlow-PyPi-FF6F00?logo=tensorflow&logoColor=white)](https://pypi.org/project/tensorflow/ "Tensorflow: PyPi.org")
 

##### <ins>TensorFlow & Keras 3</ins> (<small>Source:<sup>PyPi</sup></small>)

> Keras is a multi-backend deep learning framework, with support for JAX, TensorFlow, and PyTorch

-  It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning.
- Build and train models for computer vision, natural language processing, audio processing, timeseries forecasting, recommender systems, etc.
- To use keras, you should also install the backend of choice: `tensorflow`, `jax`, or `torch`.
- NB:  Note that `tensorflow` is required for using certain Keras 3 features: certain preprocessing `layers` as well as `tf.data` pipelines.
    - Keras 3 is intended to work as a drop-in replacement for `tf.keras` (when using the TensorFlow backend).

[![Keras.io](https://img.shields.io/badge/Keras.io-Website-d00000?logo=tensorflow&logoColor=white)](https://keras.io/ "Keras: Keras.io") <sup>|</sup> [![TensorFlow Keras](https://img.shields.io/badge/TensorFlow%20Keras-Guide-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/guide/keras "High Level API for TensorFlow's older Keras") <sup>|</sup> [![Keras.io](https://img.shields.io/badge/Keras.io-Get%20Started-d00000?logo=keras&logoColor=white)](https://keras.io/getting_started/ "Keras: Get Started Guide") <sup>|</sup> [![Keras.io](https://img.shields.io/badge/Keras.io-GitHub-d00000?logo=keras&logoColor=white)](https://github.com/keras-team/keras "Keras: GitHub.com") <sup>|</sup> [![Keras.io](https://img.shields.io/badge/Keras.io-PyPI-d00000?logo=keras&logoColor=white)](https://pypi.org/project/keras/ "Keras: PyPi.org")

<br><br>
> <hr>
> <hr>
<br><br>

### 2Ô∏è‚É£ <ins>Generative AI: Tuning Transformers: `Session 3.2`</ins>

[![Session 3.2 Tuning Transformers](https://img.shields.io/badge/Session3.2%20GenAI%20Transformers-Jumpto-5c5c5c?labelColor=3499cd&logo=googlecolab&logoColor=d39816)](https://colab.research.google.com/github/iPoetDev/ibm-skills-ai-colab-sessions/blob/main/notebooks-labs/Session3_FineTuning_BERTandGPT.ipynb#scrollTo=Wyyh4uo1sxrX "Open Session3_FineTuning_BERTandGPT.ipynb on colab.google.com")

> Foundational Models are large scale models pre-trained on vast ammount of data, broad and diverse datasets, for adaption to downstream tasks. These can be fine tuned for specific applications by building more specialized models.

- BERT, a type of transformer model, is used in this session (3.2).
    - Designed to underdstand a words's context in search queries.
    - It does this by looking at the words that come before and after it
    - It is bidirectional: BERT reads entire sequence of words one, considering the full context of each word.
    - Is excellent for understanding text and it's context, thus ideal for deep understanding and analysis of language.
- Pre-training models allows models to learn general language patterns, structures, and representations.
- Fine-tuning: The process of adapting pre-trained models to specific tasks, using smaller, task specific datasets.
    - Customises the model to improve performance in specific applications without needing to train it from scratch. 


#### <ins>Accelerate</ins>

> HuggingFace's ü§ó library that enables the same `PyTorch` code to be run across any distributed configuration. 

- It's run your *raw* `PyTorch` training script on any kind of device.
- Accerlate was created for `PyTorch` users who like to write the training loop of `PyTorch` models ..
    - ... but are reluctant to write and maintain the boilerplate code needed to use multi-GPUs/TPU/fp16.
- Accelerate abstracts exactly and only the boilerplate code related to multi-GPUs/TPU/fp16.

[![Hugging Face Website](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Accelerate-Website-blue)](https://huggingface.co/docs/accelerate/en/quicktour "HuggingFace Accelerate") <sup>|</sup> [![Hugging Face GitHub](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Accelerate-GitHub-blue)](https://github.com/huggingface/accelerate/tree/main "HuggingFace Accelerate: GitHub.com") <sup>|</sup> [![Hugging Face PyPi](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Accelerate-PyPi-blue)](https://pypi.org/project/accelerate/ "HuggingFace Accelerate: PyPi.org") 

#### <ins>Transformers</ins>

> HuggingFace provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and share them on HuggingFace's mode; hub.

-  It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.

[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Transformers-Website-blue)](https://huggingface.co/docs/transformers/en/index "HuggingFace Transformers") <sup>|</sup> [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Transformers-GitHub-blue)](https://github.com/huggingface/transformers/tree/main "HuggingFace Transformers: GitHub.com") <sup>|</sup> [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Transformers-PyPi-blue)](https://pypi.org/project/transformers/ "HuggingFace Transformers: PyPi.org")

**UseCases** (<small>Source:<sup>PyPi</sup></small>)

These models can be applied on:

- üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, and text generation, in over 100 languages.
- üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.
- üó£Ô∏è Audio, for tasks like speech recognition and audio classification.
- Transformer models can also perform tasks on several modalities combined, such as
    - Table question answering, 
    - Ooptical character recognition, 
    - Information extraction from scanned documents, 
    - Video classification, and 
    - Visual question answering.

<br>

---
> <center>...</center>
---

## References

### IBM SkillsBuild

- <sup>n</sup>
- <sup>n</sup>
- <sup>n</sup>

### IBM Developer

- <sup>n</sup> IBM Developer (2023-12-08) "Implement autoencoders using TensorFlow" (Accessed: July 2024); URL https://developer.ibm.com/tutorials/implement-autoencoders-using-tensorflow/  
- <sup>n</sup>
- <sup>n</sup>
- <sup>n</sup>

## Author

[![LinkedIn](https://img.shields.io/badge/Author-Charles%20J%20Fowler-0077B5?logo=gmail&logoColor=white)](mailto:ipoetdev-github-no-reply@outlook.com "Contact CJ on GItHub email: ipoetdev-github-no-reply@outlook.com") <sup>|</sup> [![LinkedIn](https://img.shields.io/badge/Charles%20J%20Fowler-LinkedIn-0077B5?logo=linkedin&logoColor=white)](https://ie.linkedin.com/in/charlesjfowler "@CharlesJFowler @Linkedin.com") <sup>|</sup> [![LinkedIn](https://img.shields.io/badge/iPoetDev-GitHub-0077B5?logo=GitHub&logoColor=white)](https://github.com/ipoetdev "@iPoetDev @GitHub")

## ChangeLog

| Date<sup>a</sup> | Version | Changed By | Change | Activity | 
| :--- | :--- | :--- | :--- | :--- | 
| 2024-07-16  | 0.1 | Charles J Fowler  | Initial version created | Create  | 
| 2024-07-27  | 0.2 | Charles J Fowler  | Draft Portfolio version | Modify  | 
<sup>a</sup>: `YYYY-MM-DD`